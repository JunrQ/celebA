{
  'trainer' : {
    'benchmark' : True,
    'check_val_every_n_epoch' : 5,
    'gradient_clip_val' : 0.0, # 0 means no
    'log_gpu_memory' : True, # Just log
    'max_epochs' : 200,
    'num_sanity_val_steps' : 2,
  },

  'batch_size' : 256,

  'model' : {
    'depth' : 18, # 50,
    'num_classes' : 40,
    'pretrained' : True,
  },

  'criterion' : {
    'type' : 'BCELoss',
  },

  'optimizer' : {
    'type' : 'SGD',
    'lr' : 0.1,
    'momentum' : 0.9,
    'weight_decay' : 1e-4,
  },

  'scheduler' : {
    'type' : 'MultiStepLR',
    'milestones' : [50, 90, 120, 150, 180], # 200K images, 128 batch size
    'gamma' : 0.1,
    # 'lr_lambda' : lambda steps : 0.99 ** steps,
  },

  # ---------- Dataset parameters ----------
  'train_dataset' : {
    'path' : 'data',
    'transform' : {
      'type' : 'Compose',
      'params' : [
        ('RandomHorizontalFlip', ([], {})),
        ('ToTensor' , ([], dict())),
        ('Normalize' , ([(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)], dict()))
      ]
    },
  },
  'valid_dataset' : {
    'path' : 'data',
    'transform' : {
      'type' : 'Compose',
      'params' : [
        ('ToTensor' , ([], dict())),
        ('Normalize' , ([(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)], dict()))
      ],
    }
  },
  'test_dataset' : {
    'path' : 'data',
    'transform' : {
      'type' : 'Compose',
      'params' : [
        ('ToTensor' , ([], dict())),
        ('Normalize' , ([(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)], dict()))
      ],
    }
  },
}
